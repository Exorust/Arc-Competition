{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41822552-3244-4b0f-b655-a8b1d3392c15",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è Local Benchmark for ARC-AGI\n",
    "\n",
    "This notebook is designed to **evaluate your ARC-AGI solution locally** on your machine. It provides a streamlined setup for testing your approach before transitioning to the Kaggle environment. However, you may need to adjust a few paths to ensure compatibility with Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1991ab",
   "metadata": {
    "papermill": {
     "duration": 0.010814,
     "end_time": "2024-07-08T15:32:14.614024",
     "exception": false,
     "start_time": "2024-07-08T15:32:14.603210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff006920",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.035062,
     "end_time": "2024-07-08T15:32:14.659688",
     "exception": false,
     "start_time": "2024-07-08T15:32:14.624626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "# -------------------\n",
    "from abstract_and_reason import solver_v1\n",
    "from abstract_and_reason.assets import load_json, sort_challenges_by_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f6bb8",
   "metadata": {
    "papermill": {
     "duration": 0.010881,
     "end_time": "2024-07-08T15:32:15.255718",
     "exception": false,
     "start_time": "2024-07-08T15:32:15.244837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's define our Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8226ce38-624a-4162-a19e-cdd8858a39ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abec679269eb4cd5ab4d7de23b2b06b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract_and_reason = solver_v1.Solver(prod=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96609b68",
   "metadata": {
    "papermill": {
     "duration": 0.010587,
     "end_time": "2024-07-08T15:32:14.681256",
     "exception": false,
     "start_time": "2024-07-08T15:32:14.670669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## JSON files loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bd2d1-71e5-4957-a91b-ab594636b043",
   "metadata": {},
   "source": [
    "üö®üö®üö® change `dev_path` to `prod_path` for Kaggle testing üö®üö®üö®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724ac741",
   "metadata": {
    "papermill": {
     "duration": 0.020352,
     "end_time": "2024-07-08T15:32:14.712287",
     "exception": false,
     "start_time": "2024-07-08T15:32:14.691935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_path = '../data/challenges/' # your own challenge directory\n",
    "prod_path = '/kaggle/input/arc-prize-2024/' # path may change in 2025 arc-prize\n",
    "\n",
    "base_path = dev_path # /!\\ change dev_path to prod_path for Kaggle testing\n",
    "\n",
    "\n",
    "submission_file_path = './submission.json'\n",
    "sample_submission_file_path = base_path + 'sample_submission.json'\n",
    "\n",
    "training_challenges = abstract_and_reason.training_challenges\n",
    "training_solutions = abstract_and_reason.training_solutions\n",
    "evaluation_challenges = abstract_and_reason.evaluation_challenges\n",
    "evaluation_solutions = abstract_and_reason.evaluation_solutions\n",
    "test_challenges = abstract_and_reason.test_challenges\n",
    "sample_submission = abstract_and_reason.sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b06065-da76-4872-a6c2-5da8128112eb",
   "metadata": {},
   "source": [
    "## Submission file creation and filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223ee12-e14f-430a-aa77-025d6e0c4624",
   "metadata": {},
   "source": [
    "The submission file is filled with 2 wrong attemps for each challenge, which makes it ready to get evaluated. \n",
    "\n",
    "Next cells bellow will fill the challenges answers using your own solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4d8fb8-9cd0-4773-9dba-6f23c5e5fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(submission_file_path, \"w\") as file:\n",
    "        json.dump(sample_submission, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fe763",
   "metadata": {
    "papermill": {
     "duration": 0.011463,
     "end_time": "2024-07-08T15:32:15.926317",
     "exception": false,
     "start_time": "2024-07-08T15:32:15.914854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08ea1e9",
   "metadata": {
    "papermill": {
     "duration": 0.02201,
     "end_time": "2024-07-08T15:32:15.961345",
     "exception": false,
     "start_time": "2024-07-08T15:32:15.939335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write python DSL code to solve the puzzle.\n",
      " DSL:['identity', 'add', 'subtract', 'multiply', 'divide', 'invert', 'even', 'double', 'halve', 'flip', 'equality', 'contained', 'combine', 'intersection', 'difference', 'dedupe', 'order', 'repeat', 'greater', 'size', 'merge', 'maximum', 'minimum', 'valmax', 'valmin', 'argmax', 'argmin', 'mostcommon', 'leastcommon', 'initset', 'both', 'either', 'increment', 'decrement', 'crement', 'sign', 'positive', 'toivec', 'tojvec', 'sfilter', 'mfilter', 'extract', 'totuple', 'first', 'last', 'insert', 'remove', 'other', 'interval', 'astuple', 'product', 'pair', 'branch', 'compose', 'chain', 'matcher', 'rbind', 'lbind', 'power', 'fork', 'apply', 'rapply', 'mapply', 'papply', 'mpapply', 'prapply', 'mostcolor', 'leastcolor', 'height', 'width', 'shape', 'portrait', 'colorcount', 'colorfilter', 'sizefilter', 'asindices', 'ofcolor', 'ulcorner', 'urcorner', 'llcorner', 'lrcorner', 'crop', 'toindices', 'recolor', 'shift', 'normalize', 'dneighbors', 'ineighbors', 'neighbors', 'objects', 'partition', 'fgpartition', 'uppermost', 'lowermost', 'leftmost', 'rightmost', 'square', 'vline', 'hline', 'hmatching', 'vmatching', 'manhattan', 'adjacent', 'bordering', 'centerofmass', 'palette', 'numcolors', 'color', 'toobject', 'asobject', 'rot90', 'rot180', 'rot270', 'hmirror', 'vmirror', 'dmirror', 'cmirror', 'fill', 'paint', 'underfill', 'underpaint', 'hupscale', 'vupscale', 'upscale', 'downscale', 'hconcat', 'vconcat', 'subgrid', 'hsplit', 'vsplit', 'cellwise', 'replace', 'switch', 'center', 'position', 'index', 'canvas', 'corners', 'connect', 'cover', 'trim', 'move', 'tophalf', 'bottomhalf', 'lefthalf', 'righthalf', 'vfrontier', 'hfrontier', 'backdrop', 'delta', 'gravitate', 'inbox', 'outbox', 'box', 'shoot', 'occurrences', 'frontiers', 'compress', 'hperiod', 'vperiod'] \n",
      "Input: [array([[5, 5, 0],\n",
      "       [5, 0, 5],\n",
      "       [0, 5, 0]]), array([[8, 0, 8],\n",
      "       [0, 8, 0],\n",
      "       [8, 0, 8]]), array([[5, 0, 5],\n",
      "       [0, 5, 0],\n",
      "       [5, 0, 5]]), array([[0, 1, 1],\n",
      "       [0, 1, 1],\n",
      "       [1, 0, 0]]), array([[0, 8, 8],\n",
      "       [0, 8, 8],\n",
      "       [8, 0, 0]]), array([[4, 4, 0],\n",
      "       [4, 0, 4],\n",
      "       [0, 4, 0]]), array([[0, 5, 0],\n",
      "       [5, 5, 5],\n",
      "       [0, 5, 0]])]\n",
      "Output: [array([[1]]), array([[2]]), array([[2]]), array([[3]]), array([[3]]), array([[1]]), array([[6]])].\n",
      "Write python DSL code to solve the puzzle.\n",
      " DSL:['identity', 'add','subtract','multiply', 'divide', 'invert', 'even', 'double', 'halve', 'flip', 'equality', 'contained', 'combine', 'intersection', 'difference', 'dedupe', 'order','repeat', 'greater','size','merge','maximum','minimum', 'valmax', 'valmin', 'argmax', 'argmin','mostcommon', 'leastcommon', 'initset', 'both', 'either', 'increment', 'decrement', 'crement','sign', 'positive', 'toivec', 'tojvec','sfilter','mfilter', 'extract', 'totuple', 'first', 'last', 'insert','remove', 'other', 'interval', 'astuple', 'product', 'pair', 'branch', 'compose', 'chain','matcher', 'rbind', 'lbind', 'power', 'fork', 'apply', 'rapply','mapply', 'papply','mpapply', 'prapply','mostcolor', 'leastcolor', 'height', 'width','shape', 'portrait', 'colorcount', 'colorfilter','sizefilter', 'asindices', 'ofcolor', 'ulcorner', 'urcorner', 'llcorner', 'lrcorner', 'crop', 'toindices','recolor','shift', 'normalize', 'dneighbors', 'ineighbors', 'neighbors', 'objects', 'partition', 'fgpartition', 'uppermost', 'lowermost', 'leftmost', 'rightmost','square', 'vline', 'hline', 'hmatching', 'vmatching','manhattan', 'adjacent', 'bordering', 'centerofmass', 'palette', 'numcolors', 'color', 'toobject', 'asobject', 'rot90', 'rot180', 'rot270', 'hmirror', 'vmirror', 'dmirror', 'cmirror', 'fill', 'paint', 'underfill', 'underpaint', 'hupscale', 'vupscale', 'upscale', 'downscale', 'hconcat', 'vconcat','subgrid', 'hsplit', 'vsplit', 'cellwise','replace','switch', 'center', 'position', 'index', 'canvas', 'corners', 'connect', 'cover', 'trim','move', 'tophalf', 'bottomhalf', 'lefthalf', 'righthalf', 'vfrontier', 'hfrontier', 'backdrop', 'delta', 'gravitate', 'inbox', 'outbox', 'box','shoot', 'occurrences', 'frontiers', 'compress', 'hperiod', 'vperiod'] \n",
      "Input: [array([[5, 5, 0],\n",
      "       [5, 0, 5],\n",
      "       [0, 5, 0]]), array([[8, 0, 8],\n",
      "       [0, 8, 0],\n",
      "       [8, 0, 8]]), array([[5, 0, 5],\n",
      "       [0, 5, 0],\n",
      "       [5, 0, 5]]), array([[0, 1, 1],\n",
      "       [0, 1, 1],\n",
      "       [1, 0, 0]]), array([[0, 8, 8],\n",
      "       [0, 8, 8],\n",
      "       [8, 0, 0]]), array([[4, 4, 0],\n",
      "       [4, 0, 4],\n",
      "       [0, 4, 0]]), array([[0, 5, 0],\n",
      "       [5, 5, 5],\n",
      "       [0, 5, 0]])]\n",
      "Output: [array([[1]]), array([[2]]), array([[2]]), array([[3]]), array([[3]]), array([[1]]), array([[6]])].\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "from numpy import array\n",
      "from numpy import argmax as argmax\n",
      "from numpy import argmin as argmin\n",
      "from numpy import argwhere as argwhere\n",
      "from numpy import argsort as argsort\n",
      "from numpy import array_equal as array_equal\n",
      "from numpy import asarray as asarray\n",
      "from numpy import atleast_1d as atleast_1d\n",
      "from numpy import atleast_2d as atleast_2d\n",
      "from numpy import bool8 as bool8\n",
      "from numpy import ceil as ceil\n",
      "from numpy import concatenate as concatenate\n",
      "from\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m puzzle_inps_train, puzzle_outs_train, puzzle_inps_test, puzzle_outs_test \u001b[38;5;241m=\u001b[39m abstract_and_reason\u001b[38;5;241m.\u001b[39mprocess_challenge(challenge_id, test_challenges)\n\u001b[0;32m      9\u001b[0m attempt1 \u001b[38;5;241m=\u001b[39m abstract_and_reason\u001b[38;5;241m.\u001b[39mpredict(puzzle_inps_train, puzzle_outs_train, puzzle_inps_test)\n\u001b[1;32m---> 10\u001b[0m attempt2 \u001b[38;5;241m=\u001b[39m \u001b[43mabstract_and_reason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpuzzle_inps_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpuzzle_outs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpuzzle_inps_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(puzzle_inps_train)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(puzzle_outs_train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(puzzle_inps_test)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(attempt1)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# print(attempt2)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m \u001b[38;5;66;03m# TODO: remove this line to predict all challenges\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\Courses\\Fall-24\\ARC\\Arc-Competition\\arc-agi-genesis\\source\\abstract_and_reason\\solver_v1.py:79\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(self, puzzle_inps_train, puzzle_outs_train, puzzle_inps_test, puzzle_outs_test)\u001b[0m\n\u001b[0;32m     65\u001b[0m def predict(self, puzzle_inps_train, puzzle_outs_train, puzzle_inps_test, puzzle_outs_test=None):\n\u001b[0;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m     67\u001b[0m     Predicts the outputs for test puzzles based on training inputs and outputs.\n\u001b[0;32m     68\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         list: Predicted outputs for the test puzzles.\n\u001b[0;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m     78\u001b[0m     try:\n\u001b[1;32m---> 79\u001b[0m         # Your board prediction solution goes here !\n\u001b[0;32m     80\u001b[0m         prompt = 'Write python DSL code to solve the puzzle.\\n DSL:{dsl} \\nInput: {input}\\nOutput: {output}.'\n\u001b[0;32m     81\u001b[0m         prompt = prompt.format(dsl=find_function_names(\"C:\\\\Users\\\\chand\\\\Courses\\\\Fall-24\\\\ARC\\\\Arc-Competition\\\\arc-agi-genesis\\\\source\\\\abstract_and_reason\\\\dsl\\\\dsl.py\"), input=puzzle_inps_train, output=puzzle_outs_train)\n",
      "File \u001b[1;32mc:\\Users\\chand\\Courses\\Fall-24\\ARC\\Arc-Competition\\arc-agi-genesis\\source\\abstract_and_reason\\solver_v1.py:56\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(self, prompt, max_length, temperature)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Tokenize the input prompt\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Generate the output\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids, max_length\u001b[38;5;241m=\u001b[39mmax_length, temperature\u001b[38;5;241m=\u001b[39mtemperature)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\generation\\utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[0;32m   1510\u001b[0m         input_ids,\n\u001b[0;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1524\u001b[0m     )\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_greedy_search(\n\u001b[0;32m   1528\u001b[0m         input_ids,\n\u001b[0;32m   1529\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1530\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1531\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1532\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1533\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1534\u001b[0m         output_logits\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_logits,\n\u001b[0;32m   1535\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1536\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1537\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1539\u001b[0m     )\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\generation\\utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2412\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2413\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2414\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2415\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\models\\stablelm\\modeling_stablelm.py:1114\u001b[0m, in \u001b[0;36mStableLmForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1109\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1110\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m   1111\u001b[0m )\n\u001b[0;32m   1112\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1114\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1127\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\models\\stablelm\\modeling_stablelm.py:991\u001b[0m, in \u001b[0;36mStableLmModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    982\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    983\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    984\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    988\u001b[0m         output_attentions,\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 991\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\models\\stablelm\\modeling_stablelm.py:722\u001b[0m, in \u001b[0;36mStableLmDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    719\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chand\\miniconda3\\envs\\resurgence\\lib\\site-packages\\transformers\\models\\stablelm\\modeling_stablelm.py:455\u001b[0m, in \u001b[0;36mStableLmSdpaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    452\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    453\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m--> 455\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The q_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case q_len == 1.\u001b[39;49;00m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    466\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(submission_file_path, \"r+\") as outfile:\n",
    "    submission_data = json.load(outfile)\n",
    "    \n",
    "    ids_test = sort_challenges_by_size(test_challenges)\n",
    "\n",
    "    for i, challenge_id in enumerate(tqdm(ids_test)):\n",
    "        puzzle_inps_train, puzzle_outs_train, puzzle_inps_test, puzzle_outs_test = abstract_and_reason.process_challenge(challenge_id, test_challenges)\n",
    "        \n",
    "        attempt1 = abstract_and_reason.predict(puzzle_inps_train, puzzle_outs_train, puzzle_inps_test)\n",
    "        attempt2 = abstract_and_reason.predict(puzzle_inps_train, puzzle_outs_train, puzzle_inps_test)\n",
    "        # print(puzzle_inps_train)\n",
    "        # print(puzzle_outs_train)\n",
    "        # print(puzzle_inps_test)\n",
    "        # print(attempt1)\n",
    "        # print(attempt2)\n",
    "        break # TODO: remove this line to predict all challenges\n",
    "        \n",
    "        result = []\n",
    "        for j in range(len(attempt1)):\n",
    "            result.append({\n",
    "                'attempt_1': attempt1[j].tolist(),\n",
    "                'attempt_2': attempt2[j].tolist()\n",
    "            })\n",
    "        \n",
    "        submission_data[challenge_id] = result\n",
    "        \n",
    "        outfile.seek(0)\n",
    "        json.dump(submission_data, outfile, indent=4)\n",
    "        outfile.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c31f7-91a0-4b8b-b45e-24c8a4289cd7",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c71fd9-0a68-41a5-8fad-bd47a3d5488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_score(model_answers, real_answers):\n",
    "    \"\"\"\n",
    "    Computes a score based on the similarity between model-generated answers and real answers.\n",
    "    It handles input matrices of different shapes and ensures comparisons are done within the bounds of the shortest list.\n",
    "\n",
    "    Args:\n",
    "        model_answers (list of lists): Model-generated answers as matrices (list of lists).\n",
    "        real_answers (list of lists): Real answers as matrices (list of lists).\n",
    "\n",
    "    Returns:\n",
    "        int: The total score as an integer.\n",
    "    \"\"\"\n",
    "    total_score = 0\n",
    "    valid_comparisons = 0\n",
    "    \n",
    "    for i in range(min(len(model_answers), len(real_answers))):\n",
    "        model_answer = np.array(model_answers[i])\n",
    "        real_answer = np.array(real_answers[i])\n",
    "        \n",
    "        if model_answer.shape == real_answer.shape:\n",
    "            score = ((model_answer == real_answer).astype(int)).mean()\n",
    "            if score == 1.0:\n",
    "                total_score += 1\n",
    "            valid_comparisons += 1\n",
    "    \n",
    "    return int(total_score / valid_comparisons) if valid_comparisons > 0 else 0\n",
    "\n",
    "\n",
    "def get_anwser(challenge_id, answers_file_path):\n",
    "    sample_submission = load_json(answers_file_path)\n",
    "    challenge = sample_submission[challenge_id]\n",
    "    return challenge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dda161-1b13-4063-8105-e6520840e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final score: 100.0\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "\n",
    "with open(submission_file_path, \"r\") as outfile: # previously 'r+'\n",
    "    submission_data = json.load(outfile)\n",
    "    \n",
    "    ids_test = sort_challenges_by_size(test_challenges)\n",
    "\n",
    "    for i, challenge_id in enumerate(ids_test):\n",
    "\n",
    "        ground_truth = get_anwser(challenge_id, sample_submission_file_path)\n",
    "        model_answer = get_anwser(challenge_id, submission_file_path)\n",
    "\n",
    "        challenge_score = 0\n",
    "        for attempt in ground_truth.keys():\n",
    "            challenge_score += get_score(model_answer[attempt], ground_truth[attempt])\n",
    "\n",
    "        total_score += (challenge_score)/2\n",
    "\n",
    "print(f\"\\n\\nFinal score: {total_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9670dd9a",
   "metadata": {},
   "source": [
    "### üí° Save Yourself the Headache! üí°\n",
    "\n",
    "I've made the mistakes so you don't have to! Now, you'll save tons of time working on ARC-AGI. \n",
    "\n",
    "If this notebook helped you avoid common pitfalls or sped up your progress, I'd love your support!\n",
    "\n",
    "- **Follow me on Kaggle:** [Malo Le Mestre](https://www.kaggle.com/malolem)\n",
    "- **Leave a ‚≠ê on the GitHub repo** [here](https://github.com/MaloLM/arc-agi-genesis) to show your appreciation and keep the project growing!\n",
    "- **Upvote this notebook** on Kaggle if it saved you from banging your head against the wall!\n",
    "\n",
    "Your feedback keeps me motivated and helps others avoid the same challenges. \n",
    "\n",
    "# Thank you! üöÄ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "resurgence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.359109,
   "end_time": "2024-07-08T15:32:16.718057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-08T15:32:11.358948",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
